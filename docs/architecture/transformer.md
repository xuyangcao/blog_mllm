# Transformer 架构详解

> TODO: 待补充内容

## Transformer 基本结构

### Self-Attention

### 多头注意力

### 位置编码

### Feed-Forward Network

### LayerNorm 与残差连接

## Transformer 优化与改进

### RoPE / ALiBi

### KV Cache 原理

