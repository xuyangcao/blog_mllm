# 书籍定位与读者群

这本书的定位是：**面向“要把模型做出来、跑起来、上线起来”的研究/工程读者**，把大模型（LLM）与多模态大模型（MLLM）的关键原理、训练方法与系统工程串成一条可复用的主线。

它不是“百科”，也不是“论文导读合集”。你会看到的写法更像：

- 先把问题抽象清楚（目标函数/约束/评测）
- 再把核心机制讲透（公式→直觉→实现）
- 最后落到工程决策（为什么这样做、有哪些坑、如何验证）

---

## 写作目标（本书想解决的痛点）

很多技术文章要么只讲公式不谈实现，要么只贴代码不解释原理。本书希望架起两者之间的桥梁：

1. **公式拆解**：不只列出公式，而是逐层拆解，解释每个符号的含义和设计意图
2. **类比辅助**：用熟悉的概念类比陌生领域，降低理解门槛
3. **工程视角**：解释“为什么这样设计”，以及常见失败模式与稳定性问题
4. **代码对照**：给出伪代码或核心实现，帮助把数学公式映射到可运行的工程

---

## 本书会讲什么（Scope）

### 1) 统一的模型主线：Transformer → LLM → MLLM

- Transformer 的核心模块（Attention、位置编码、KV cache 等）
- LLM 的架构设计与成本权衡（Decoder-only、tokenization、量化/稀疏）
- MLLM 的对齐与融合（双塔/单塔、cross-attn、对比学习与生成）

### 2) 统一的训练主线：预训练 → 指令化 → 对齐 → 推理部署

- 数据准备与治理（质量、分布、噪声、可追溯）
- 大规模训练技术（并行、混合精度、显存与通信）
- 对齐方法（RLHF/GRPO 等；核心是 reward/约束/评测）
- 推理与部署（KV cache、batching、量化、系统可观测与安全）

### 3) 统一的工程主线：可控、可验证、可迭代

本书会反复强调三个“上线必需品”：

- **可验证**：输出能否被程序/规则/执行反馈验证？
- **可审计**：模型依据的事实来自哪里？能否追溯？
- **可迭代**：线上问题能否变成数据/规则/训练信号？

---

## 本书不讲什么（Non-goals）

- 不追求覆盖所有论文与所有模型（会选典型路线讲透）
- 不把“堆结论”当作学习（会尽量给出推导与可复用的直觉）
- 不把“跑通 demo”当作工程完成（会强调监控、成本、失败模式与治理）

---

## 适合谁读

如果你符合下面任意一种画像，会非常合适：

- **工程侧**：要训练/微调/部署 LLM/MLLM，希望理解每个模块的成本与风险
- **研究侧**：能看论文，但希望把公式与实现对齐，并知道“评测是否可信”
- **产品/架构侧**：要做技术决策，希望拿到一套可落地的权衡框架（而不是 SOTA 罗列）

如果你正在做以下方向的研究或工程工作，也会非常合适：

- 多模态大模型（VLM、MLLM）
- 大语言模型训练与优化
- 分布式训练与推理加速
- 强化学习对齐（RLHF、GRPO、PPO）

---

## 阅读方式（建议路线）

你可以按两种方式阅读：

### 方式 A：从“模型原理”一路读到“上线”

1. 基础理论（LLM 概述 / DL / 多模态）
2. 核心架构（Transformer → LLM 设计 → MLLM 架构）
3. 训练与优化（数据 → 分布式训练 → 对齐 → 推理部署）
4. 应用与实战（多模态应用、智能体、工程实战）

### 方式 B：按“你要解决的问题”跳读

- 做长上下文/高并发推理：优先看 KV cache、GQA/MQA、batching、量化
- 做多模态对话/看图问答：优先看 MLLM 架构、对齐数据、理解 vs 生成的差异与评测
- 做对齐与 RL：优先看 RL 对齐章节与 GRPO 详解，并补齐 reward/评测闭环

---

## 章节质量声明（你如何判断“这一章值得信任”）

每章尽量满足以下标准：

- 给出明确的**问题定义**（输入/输出/目标/约束）
- 给出关键机制的**公式与直觉解释**
- 给出可落地的**工程要点与坑位清单**
- 能回答“如何验证它有效/如何定位失败”


