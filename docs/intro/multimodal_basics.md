# 多模态基础

> 目标：建立一个统一视角：不同模态如何表示、如何对齐、如何融合，以及常见任务如何评测与落地。

## 什么是多模态数据

“模态（modality）”可以理解为信息的载体形式。多模态数据的特点是：同一语义可由不同模态共同描述，并且模态之间存在互补与冗余。

常见模态：

- **文本**：离散 token 序列，强语义、弱感知细节
- **图像**：二维像素或 patch，强感知细节、弱显式结构
- **语音**：时序信号（波形/频谱），包含内容与说话人/情绪等因素
- **视频**：图像 + 时间维度 + 动作/事件
- **3D/点云**：几何结构与空间关系，常用于机器人与自动驾驶

多模态问题的难点不在于“多一种输入”，而在于：

- **对齐（alignment）**：不同模态在时间/空间/语义层面如何对应？
- **融合（fusion）**：在什么层面把信息合在一起最有效？
- **监督信号**：标注成本高、噪声大、分布偏差严重。

## 多模态数据表示

核心问题是：如何把不同模态变成统一可计算的表示 \(z\)。

### 连续表征：encoder 输出向量/序列

- 图像：CNN/ViT 把图像变成 patch token 序列 \(\{v_i\}\)
- 语音：wav2vec/Conformer 把语音变成帧级 token 序列 \(\{a_t\}\)
- 文本：Transformer 把 token 变成隐藏状态 \(\{h_t\}\)

### 离散 token 化：把模态变成“可语言化”的符号

一种常见工程思路是把连续信号量化成离散 token（例如 VQ-VAE），从而复用语言模型的建模方式。优点是统一接口，缺点是量化误差与训练复杂度。

### 表示学习的目标：对齐与可分性

表示是否“好用”往往体现在两点：

- **对齐**：同一语义的跨模态样本距离更近（例如图文对齐）
- **可分性/可线性读出**：下游任务能否用简单头部实现高性能

## 多模态融合方法

多模态融合可以按发生位置分三类（你可以把它当成工程选型的“总纲”）。

### 早期融合（Early Fusion）

在较早层就把模态拼在一起（例如把视觉 token 与文本 token 直接拼接进同一个 Transformer）。

- 优点：交互充分，适合复杂推理与细粒度对齐
- 缺点：计算开销大，对数据质量敏感

### 晚期融合（Late Fusion）

先分别编码，再在高层融合（例如双塔 + 相似度/MLP）。

- 优点：高效、易部署，适合检索与匹配
- 缺点：交互受限，对“需要逐步推理”的任务不够强

### 交互式融合（Cross-Attention / Co-Attention）

让一个模态去 attend 另一个模态的表示（例如文本 query 去 attend 图像 key/value），是很多 VLM/MLLM 的核心组件。

- 优点：表达力强且比全量早期融合更可控
- 缺点：实现与加速更复杂（KV Cache、跨模态长度差异等）

## 多模态任务类型

从“输出形态”划分，最常见的任务包括：

- **分类/检测/分割**：输出离散标签或结构化结果（CV 传统任务）
- **检索（Retrieval）**：图搜文、文搜图，核心是对齐表示与相似度学习（CLIP 系）
- **生成（Generation）**：图像描述、视频字幕、语音转写、文本引导图像生成
- **问答（VQA）**：给定图像/视频与问题，生成答案；对推理链与对齐要求更高

从“训练信号”划分，还常见：

- **对比学习（Contrastive）**：强于表征与检索
- **掩码建模（Masked Modeling）**：强于理解与补全
- **自回归生成（Autoregressive）**：强于统一生成接口与对话式应用

---

## 工程落地：你需要优先解决的 4 个问题

1. **数据对齐与噪声**：图文对是否真的对应？是否存在模板化 caption、脏标签、重复样本？
2. **评测是否反映真实需求**：检索指标（Recall@K）不等于“业务可用”；生成指标（BLEU/CIDEr）不等于“事实正确”。
3. **系统延迟与成本**：视觉编码器与跨注意力往往是瓶颈；需要 batch、cache、量化与算子融合。
4. **可控性与安全**：多模态更容易引入“看图胡说/过度自信”；需要引用证据、拒答与安全策略。

---

## 本章小结

- 多模态的难点集中在：对齐、融合与监督信号质量。
- 融合策略可按早期/晚期/交互式理解，直接指导架构选型。
- 真实落地优先关注数据、评测、成本与可控性，而不是只追 SOTA。

