# 深度学习基础回顾

> 目标：用最短路径回顾后续章节会高频用到的概念：反向传播、优化、正则化、数值稳定、GPU/分布式基础。

## 神经网络基础

神经网络可以看成一族可微函数 \(f_\theta(\cdot)\)。训练的本质是：给定数据分布上的样本 \((x, y)\)，最小化经验风险：

\[
\min_\theta \ \mathbb{E}_{(x,y)\sim \mathcal{D}}\big[\ell(f_\theta(x), y)\big]
\]

在 LLM/MLLM 中，\(x\) 往往是 token 序列（或视觉 token），\(y\) 是下一个 token 或目标序列。

### 线性层、非线性与表示能力

如果只有线性变换，多个线性层仍等价于一个线性层；**非线性激活**让网络具备更强的表示能力。工程上常见的激活包括 ReLU、GELU、SiLU（Swish）。

### 损失函数与训练信号

你可以把损失函数理解为“训练信号的接口”。不同任务里常见的损失包括：

- 分类：交叉熵
- 回归：MSE / Huber
- 对比学习：InfoNCE 等
- 生成：序列交叉熵（teacher forcing）

## 前向传播与反向传播

### 前向传播：从输入到损失

给定输入 \(x\)，模型输出 \(\hat{y}=f_\theta(x)\)，再计算损失 \(\ell(\hat{y},y)\)。

### 反向传播：链式法则 + 计算图

反向传播本质是链式法则在计算图上的高效实现：

\[
\frac{\partial \ell}{\partial \theta} = \frac{\partial \ell}{\partial \hat{y}}\cdot \frac{\partial \hat{y}}{\partial \theta}
\]

工程上需要掌握的不是推导，而是三个“坑”：

- **梯度消失/爆炸**：深层网络或长序列中常见；对策包括残差、归一化、合适初始化、梯度裁剪。
- **数值稳定性**：softmax、logsumexp、混合精度下的溢出/下溢；对策包括稳定实现与 loss scaling。
- **内存与算力**：反传需要保存中间激活；对策包括梯度检查点（activation checkpointing）。

## 激活函数、正则化、优化器

### 激活函数：为什么 LLM 常用 GELU/SiLU

LLM 中常见的 MLP 激活是 GELU/SiLU。直觉上它们比 ReLU 更“平滑”，在大规模训练中更稳定。

### 正则化：不要只想到 dropout

正则化的目标是控制泛化误差与过拟合。在大模型里更常见的是：

- **权重衰减（AdamW）**：比 L2 正则更符合 Adam 的更新形式
- **数据正则化**：更大更干净的数据、去重、混洗、分布控制
- **早停与评测集监控**：在成本高的训练里尤为重要

dropout 在某些 LLM 训练配方里反而会被减弱或去掉，取决于架构与数据规模。

### 优化器：SGD → Adam → AdamW

以 Adam 为代表的自适应优化器在大模型训练中非常常见。你可以记住一个工程结论：

- 训练大模型时，**学习率调度（warmup + decay）** 往往比“换一个优化器”更关键。

常见配方：

- warmup：前 1%～5% 步数线性升学习率
- decay：cosine / linear decay
- 梯度裁剪：防止异常 batch 导致不稳定

## 常用深度学习框架介绍（PyTorch / TensorFlow）

这本书后续默认以 PyTorch 生态为主（训练、分布式、推理加速），原因是：

- 研究与工程社区活跃、调试友好
- 分布式与混合精度工具链成熟（torch.distributed、FSDP、DeepSpeed 等）

你需要掌握的最小集合：

- 张量与自动求导（autograd）
- 模型/参数/优化器状态的保存与恢复（checkpoint）
- 数据加载（DataLoader）与随机性控制（seed）

## GPU / 分布式训练基础

### GPU：你真正需要理解的 3 件事

- **带宽 vs 算力**：很多算子受显存带宽限制，不是 FLOPs。
- **kernel 启动与算子融合**：小算子过多会被启动开销吞噬，融合能显著提速。
- **显存**：参数、梯度、优化器状态、激活四大块，训练大模型的瓶颈往往是显存。

### 分布式：从数据并行到混合并行

大模型训练通常会组合使用：

- **数据并行（DP）**：不同 GPU 处理不同 batch，梯度 all-reduce
- **张量并行（TP）**：把矩阵乘拆到多卡
- **流水线并行（PP）**：把网络层切到不同卡
- **ZeRO/FSDP**：把参数/梯度/优化器状态分片，降低单卡显存

> 后续 `training/distributed.md` 会把这些展开，并给你“如何选并行策略”的工程决策树。

---

## 本章小结

- 训练的本质是最小化损失；反向传播是链式法则的工程化实现。
- 大模型训练更关注稳定性与系统效率：数值稳定、显存、通信、调度策略。
- 框架层面优先掌握 checkpoint、分布式基本概念与可复现性控制。
