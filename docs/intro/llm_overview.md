# 大模型概述

> 目标：用“工程 + 研究”的视角，快速建立对 LLM 的**问题定义、能力边界、常见误区**的统一认知。

## 什么是大模型（Large Model / LLM）

“大模型”在工程语境里通常指：**参数量、数据量、训练算力足够大**，并在统一的预训练任务上获得“通用表示能力”的模型体系。

对 LLM 来说，最核心的抽象是：用一个参数化分布 \(p_\theta\) 去建模文本序列的生成过程。最常见的形式是自回归语言建模：

\[
p_\theta(x_{1:T}) = \prod_{t=1}^{T} p_\theta(x_t \mid x_{<t})
\]

训练目标（最大似然）等价于最小化交叉熵损失：

\[
\mathcal{L}(\theta) = -\sum_{t=1}^{T} \log p_\theta(x_t \mid x_{<t})
\]

### 你需要抓住的 3 个关键词

- **规模（Scaling）**：参数/数据/算力的联合扩展带来“性能可预测提升”，并出现一些涌现现象（但“涌现”本身也存在统计与评估争议）。
- **通用表征（Representation）**：预训练不等于“会做任务”，而是获得一个可迁移的表征空间，后续要通过指令微调、对齐、工具使用等把能力“对齐到可用形态”。
- **生成式接口（Generative Interface）**：输入输出都变成 token 序列，任务被统一成“条件生成”问题——这是 LLM 能横跨多任务的关键。

### 常见误解

- **误解 1：大模型=知识库**。LLM 不直接存“事实表”，它存的是对训练分布的统计压缩；检索增强（RAG）/工具调用/外部记忆通常是把“可更新事实”从参数里剥离出去。
- **误解 2：会说=会做**。语言流畅与决策正确是两件事；尤其在高风险场景必须用约束、校验和可审计证据链补齐（你在医疗项目那篇里已经指出了这一点）。
- **误解 3：只要再训就行**。很多失败来自问题定义（reward、标签、约束）不成立，而不是模型容量不够。

## 大模型的发展历程

这里给一个“对工程最有用”的发展脉络：**目标函数如何演进、数据如何组织、对齐如何落地**。

### 1) 预训练时代：从词向量到 Transformer

- **词向量/上下文表征**：word2vec、GloVe、ELMo 等让“语义”从离散符号变成连续向量，但能力有限。
- **Transformer（2017）**：注意力机制解决长依赖、并行训练友好，成为 LLM 的主干架构。

### 2) 规模化时代：Scaling Law 与通用能力

工程上最重要的变化是：当模型、数据、算力按一定比例扩展时，**loss 与下游性能更可预测**，从而可以做“算力预算下的最优配比”。

### 3) 指令化与对齐：从“会续写”到“可对话”

把 LLM 变成可用产品，通常会经过：

- **SFT（指令微调）**：让模型学会“遵循指令/输出格式/多轮对话”。
- **对齐（RLHF / DPO / GRPO 等）**：把“人类偏好、安全性、风格约束”注入模型，使其更符合使用目标。
- **工具与系统化（Tool use / Agents）**：把能力拆到系统层：检索、执行、规划、校验、记忆、权限控制。

> 经验法则：越靠近真实业务，越不要把“正确性/安全性/约束”寄希望于端到端参数学习，而要系统化拆解。

## 大模型的能力与局限

### 能力：为什么 LLM “看起来很通用”

从机制上可以这样理解：

- **上下文学习（In-Context Learning）**：在 prompt 中给例子，相当于在推理时“临时定义任务”，模型用表征和注意力把模式匹配出来。
- **组合泛化**：语言本身高度组合，使得模型可以在已见片段上重组出新表达。
- **统一接口**：分类/抽取/生成/推理都能被写成“条件生成”。

### 局限：你必须显式防范的 5 类风险

1. **幻觉（Hallucination）**：在信息不足时仍然高置信生成；对策通常是 RAG、引用证据、校验器、拒答策略。
2. **不确定性不可见**：token 概率不等于“任务置信度”；对策是引入校准、对抗评测、结构化验证（例如规则/单元测试/执行反馈）。
3. **分布外退化（OOD）**：真实场景 OOD 是常态；对策是监控、数据闭环、回滚与安全兜底。
4. **长上下文与记忆错觉**：能看很多 token 不代表能稳定利用；对策是结构化上下文（检索、摘要、分段、计划）。
5. **对齐税（Alignment Tax）**：安全与服从可能牺牲部分开放域能力；需要分级策略（内部模型/外部模型、不同 policy）。

### 一个工程视角的检查清单

当你说“我要在业务里用 LLM”，建议先回答：

- **输入是否可审计**：模型依据的事实来自哪里？能否追溯？
- **输出是否可验证**：能否用程序/规则/执行反馈验证？
- **失败是否可控**：失败时是否能安全降级（fallback）？
- **成本是否可预测**：token 成本、延迟、峰值 QPS 下的资源预算？
- **数据是否会闭环**：线上错误能否变成训练数据或规则修正？

## 多模态大模型简介

多模态大模型（VLM/MLLM）的核心变化不是“加了图片”，而是把不同模态 \(x^{(m)}\) 映射到**同一个可对齐的表示空间**，并让语言模型成为统一的“推理与生成接口”。

常见范式包括：

- **双塔/对比学习（CLIP 系）**：图像编码器与文本编码器对齐，适合检索与表征。
- **单塔/融合式（BLIP、Flamingo 等）**：视觉特征作为条件输入喂给语言模型，适合生成与问答。
- **统一 token 化（离散视觉 token / patch token）**：把视觉变成“可被 Transformer 处理的序列”。

工程上最关键的两点：

1. **对齐数据质量**：图文对齐数据的噪声、偏差会直接反映在模型行为上。
2. **接口设计**：视觉信息以什么形式进入 LLM（prefix、cross-attn、插入 token）会影响可控性与推理效率。

## 应用场景概览

把应用按“可验证性/风险等级”粗略分层，会更容易落地：

### 低风险、可容错（优先落地）

- 文本/代码辅助：写作、总结、翻译、代码补全
- 知识管理：RAG + 摘要 + 引用
- 多模态理解：图片说明、OCR 后理解、检索

### 中风险、需要校验（需要系统化）

- 工单/客服：必须有工具调用与权限控制
- 数据分析：需要执行器（SQL/Python）与结果回传校验
- 自动化工作流：需要可观测性、回滚与审计日志

### 高风险（强约束 + 人在回路）

- 医疗、金融、法律、安防等：必须把硬约束与责任链放在系统层，模型只做“候选 + 解释 + 交互”，而不是“决策输出”。

---

## 本章小结

- LLM 的本质是对序列分布的参数化建模，预训练提供通用表征，但“可用”通常依赖 SFT/对齐/系统化。
- 工程落地优先考虑：可审计、可验证、可控失败、成本可预测、数据闭环。
- 多模态的关键不是“多一个输入”，而是对齐与接口设计：让语言模型成为统一推理接口。

