# 数据准备与处理

数据是大模型训练中“最贵、也最容易被低估”的部分：同样的模型与算力，不同的数据分布与质量，最终效果可以差一个数量级。

本章目标：

- 给出多模态训练数据的**采集 → 清洗 → 对齐 → 增强 → 特征化**全链路
- 明确哪些问题应当在数据层解决，哪些应当交给模型/训练策略
- 提供可落地的工程检查清单（避免“训练跑通了但模型不可用”）

## 多模态数据集收集

### 数据源类型

- **公开数据集**：覆盖广但噪声较大
- **业务数据**：贴近目标分布，但标注与合规成本高
- **合成数据**：成本低但易引入偏差（需要评测与约束）

### 合规与隐私（必须前置）

尤其是医疗、金融等领域，数据治理不是附加项，而是系统设计的一部分：

- 数据脱敏与访问控制
- 数据使用授权、可追溯审计
- 训练数据“可删除”（right to be forgotten）策略（视合规要求）
## 数据清洗与标注

### 清洗：先解决“明显坏数据”

常见清洗项：

- **去重**：URL/文本近重复、图像近重复（感知哈希/embedding）
- **过滤**：低分辨率、损坏文件、极端宽高比、OCR 噪声
- **语言与脚本识别**：防止语种分布失控
- **安全过滤**：NSFW、个人隐私、敏感内容

### 标注：把“任务定义”显式化

多模态标注常见形式：

- caption（描述）
- QA（问答对）
- grounding（框/区域与文本对应）
- 对话（多轮）

工程建议：

- 优先标注“可验证”的部分（例如结构化字段、可对齐证据）
- 对高风险业务，强制保留证据链（例如引用来源、关键字段对齐）
## 数据增强策略

### 图像增强

常见增强：

- resize/crop、颜色扰动、随机翻转
- 轻量模糊/压缩噪声（提升鲁棒性）

注意：多模态对齐任务里，**增强不能破坏语义对齐**。例如：

- 把文字区域裁掉会让 OCR/图文对齐崩溃
- 过强颜色扰动可能改变“红灯/绿灯”等语义
### 文本增强

常见增强：

- 同义改写、回译（back-translation）
- 模板化字段扰动（日期/数值/单位）

注意：增强要服务于目标分布，不要把“语言花活”当成质量提升。
### 对齐数据增强

多模态最关键的增强是“对齐增强”，目标是提升模型学到的对齐信号强度：

- **硬负样本（hard negatives）**：给定图像，配一个语义相近但不匹配的文本（或反之）
- **局部对齐**：把图像区域/patch 与关键词做更细粒度对齐（如果你的任务需要）
- **格式约束**：强制输出引用或结构化字段，让监督更可验证
## Tokenization 与 Feature Extraction

### 文本端：tokenization 决定成本上限

- tokenization 影响序列长度，直接影响训练与推理成本
- 对包含大量数字/代码/特殊符号的场景，建议专门评估 token 膨胀率

### 视觉端：从像素到视觉 token

常见做法：

- ViT patch embedding：把图像切成 patch，并映射到 token 序列
- 视觉 encoder 输出的 token 数（patch 数）会显著影响 cross-attn 的成本

### 缓存与离线特征

对于双塔/检索类任务，离线缓存 image/text embedding 可以显著降低在线成本；对于单塔生成式 MLLM，是否缓存视觉特征取决于你的服务形态（是否多轮、多图、是否复用同一张图）。

---

## 工程检查清单（上线前逐条过）

- **数据分布**：训练/验证/线上是否一致？是否存在明显 domain shift？
- **重复与泄漏**：训练集是否泄漏到评测集（尤其是公开 benchmark）？
- **噪声占比**：caption 错配率、模糊图占比、OCR 噪声占比？
- **长度与成本**：token 平均长度与 P95/P99 是多少？会不会把 attention 成本拉爆？
- **安全与合规**：是否可追溯？是否可删除？是否有敏感过滤？

---

## 本章小结

- 数据决定上限：先把“坏数据/错配/泄漏/分布失控”解决掉，再谈模型结构。
- 多模态的核心是对齐信号：对齐增强与证据链往往比“更大模型”更直接有效。
- 把成本指标（token 长度、patch 数、P95/P99）前置，会节省大量无效训练。
